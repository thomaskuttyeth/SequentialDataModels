{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "3e0503f8-fc03-4867-8360-b2524b68ce3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "from tensorflow import keras \n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e2127773-99fb-44e2-a44e-72b860b9a68b",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = pd.read_csv('data/drugsCom_raw.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "51256fac-c2f6-469f-baed-f68401c38de5",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = np.array(texts['review'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "d32c4cad-0aa7-46ac-977d-c1785a2dcabd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# basic preprocessing of sentences and collect final preprocessed sentences in final_setences list \n",
    "final_sentences = []\n",
    "for sent in sentences:\n",
    "    words = [word for word in sent.split() if ('&' not in  word) or ('#' not in word)]  \n",
    "    final_words = []\n",
    "    for word in words:\n",
    "        if word.startswith('\"'):\n",
    "            word = word[1:]\n",
    "        if word.endswith('\"'):\n",
    "            word = word[::-1][1::][::-1]\n",
    "        if word.startswith('('):\n",
    "            word = word[1::]\n",
    "        if word.endswith(')'):\n",
    "            word = word[::-1][1::][::-1]\n",
    "        if word.endswith('.'):\n",
    "            word = word[::-1][1::][::-1]\n",
    "        if word.endswith(','):\n",
    "            word = word[::-1][1::][::-1]\n",
    "        if word.endswith(')'):\n",
    "            word = word[::-1][1::][::-1]\n",
    "        if word.endswith('.'):\n",
    "            word = word[::-1][1::][::-1]\n",
    "        if word.endswith('.'):\n",
    "            word = word[::-1][1::][::-1]\n",
    "        final_words.append(word)\n",
    "    final_text = ' '.join(final_words)\n",
    "    final_sentences.append(final_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "7887703f-4908-4096-8d3f-32cad2f73600",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I have been on this birth control for one cycle After reading some of the reviews on this type and similar birth controls I was a bit apprehensive to start Im giving this birth control a 9 out of 10 as I have not been on it long enough for a 10 So far I love this birth control! My side effects have been so minimal its like Im not even on birth control! I have experienced mild headaches here and there and some nausea but other than that ive been feeling great! I got my period on cue on the third day of the inactive pills and I had no idea it was coming because I had zero pms! My period was very light and I barely had any cramping! I had unprotected sex the first month and obviously get pregnant so very pleased! Highly recommend'"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_sentence = final_sentences[4]\n",
    "test_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "c2d737c2-8caf-4576-a976-eb0466589132",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sent_sequence = tokenizer.texts_to_sequences([test_sentence])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "id": "e7d7e220-968e-42c5-9963-292601e89a42",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sent_padded = pad_sequences([test_sent_sequence],padding = 'post',truncating='post',maxlen = 1199)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "b6880dde-815a-4d0f-a01e-d33b1a1184c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(num_words = 1000,oov_token = \"<OOV>\")\n",
    "tokenizer.fit_on_texts(final_sentences) \n",
    "word_index = tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "cb8879ea-1545-4d39-8e7f-5b8682a53883",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating sequences from the sentence tokens\n",
    "sequences = tokenizer.texts_to_sequences(final_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "8d56f9ad-ad28-4262-b3a6-1c9b00739e1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[127, 8, 121, 1, 95, 4, 37, 1, 1, 1, 16, 696, 12, 361, 183, 20, 6, 134, 386, 160, 91, 6, 77, 706, 3, 320, 17, 1, 1, 1, 3, 14, 104, 36, 606, 6, 87, 1, 2, 11, 18, 27, 33, 38, 626, 4, 213, 1, 74, 184, 303, 179, 1, 12, 74, 2, 92, 11, 730, 449, 16, 1, 36, 606, 17]\n"
     ]
    }
   ],
   "source": [
    "print(sequences[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "6a65f7ff-81cf-4fca-801d-7303c4e4647d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 1, 6]]"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# oov token usage \n",
    "TEST = ['industriliztionsdf fmy my']\n",
    "tokenizer.texts_to_sequences(TEST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "7b64bb13-9974-4ebf-830d-040587762877",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1199,)"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padded = pad_sequences(sequences,padding = 'post',truncating='post')\n",
    "# each sequences shape will be same after padding \n",
    "padded[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "554801e5-def8-436e-8c2d-9cd82cde5dcc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([127,   8, 121, ...,   0,   0,   0])"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padded[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "6a95b095-41de-4336-8491-4b6830f52fa1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(53766, 1199)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padded.shape # 1199 word tokens for each sentences, \n",
    "# we have to create embeddings for each 1199 word tokens later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "84e6b5cd-9d11-4cde-983f-d05df6e3801f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(53766,)"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences.shape # 53766 data instances "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9afa782e-3fc2-44cd-82fd-ee83362e4a8f",
   "metadata": {},
   "source": [
    "All the sentences are converted into tokens. But how do we get meaning from these word tokens: Embedding "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "7413c612-a84a-4bb1-913b-f2e90038258f",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = np.array(texts['rating'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "ab9676e7-c7d7-4ee9-9b5b-afbc224adb88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(53766, 1199)"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padded.shape # train x "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "f9587daa-aa15-4454-bbba-9107c810e95d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(53766,)"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels.shape # train target labels "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "3c5ae1b2-2bb7-41d4-9644-f71982fe9af8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(53766, 11)"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "onehot_labels = to_categorical(labels)\n",
    "onehot_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "3b3385dd-0c8a-43d8-844b-b5b057317aec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.], dtype=float32)"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "onehot_labels[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "012aa77e-b521-46e7-84e1-063229a1807b",
   "metadata": {},
   "outputs": [],
   "source": [
    "no_unique_tokens= len(word_index)\n",
    "embedding_dimension = 128\n",
    "input_length = padded.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "id": "f6ebff78-e626-4536-bc9c-7e5f8443092f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_10 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(no_unique_tokens,embedding_dimension,input_length=input_length),\n",
    "    tf.keras.layers.LSTM(64,activation='relu'),\n",
    "    tf.keras.layers.Dense(11,activation = 'softmax')\n",
    "])\n",
    "optimizer = optimizer = keras.optimizers.Adam(learning_rate=0.01)\n",
    "model.compile(\n",
    "    optimizer = optimizer,\n",
    "    loss ='categorical_crossentropy'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "id": "99d1666d-42da-4775-823e-07b30b3c299b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      " 5/79 [>.............................] - ETA: 9:07 - loss: nan "
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_11224\\2280236910.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpadded\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m10000\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0monehot_labels\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m10000\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mbatch_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m128\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mepochs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Documents\\anaconda\\envs\\dl\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 64\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     65\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\anaconda\\envs\\dl\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1407\u001b[0m                 _r=1):\n\u001b[0;32m   1408\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1409\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1410\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1411\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\anaconda\\envs\\dl\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    149\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 150\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    151\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\anaconda\\envs\\dl\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    913\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    914\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 915\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    916\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    917\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\anaconda\\envs\\dl\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    945\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    946\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 947\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    948\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    949\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\anaconda\\envs\\dl\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2452\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m   2453\u001b[0m     return graph_function._call_flat(\n\u001b[1;32m-> 2454\u001b[1;33m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[0;32m   2455\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2456\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\anaconda\\envs\\dl\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1859\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1860\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[1;32m-> 1861\u001b[1;33m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[0;32m   1862\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[0;32m   1863\u001b[0m         \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\anaconda\\envs\\dl\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    500\u001b[0m               \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    501\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 502\u001b[1;33m               ctx=ctx)\n\u001b[0m\u001b[0;32m    503\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    504\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[1;32m~\\Documents\\anaconda\\envs\\dl\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     54\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[1;32m---> 55\u001b[1;33m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[0;32m     56\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.fit(x = padded[:10000],y = onehot_labels[:10000],batch_size = 128,epochs = 5,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "id": "54d089cd-06a5-4b59-946d-5618fc78003a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_9 (Embedding)     (None, 1199, 128)         4293888   \n",
      "                                                                 \n",
      " lstm_9 (LSTM)               (None, 64)                49408     \n",
      "                                                                 \n",
      " dense_17 (Dense)            (None, 11)                715       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4,344,011\n",
      "Trainable params: 4,344,011\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "id": "7af676f4-bd95-436d-84ba-11e75280893b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 446ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.00036795, 0.17296182, 0.04106217, 0.04856793, 0.03616836,\n",
       "        0.04449897, 0.03559168, 0.05467949, 0.11750646, 0.16739662,\n",
       "        0.28119853]], dtype=float32)"
      ]
     },
     "execution_count": 332,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_case1 = np.array([padded[9],])\n",
    "model.predict(test_case1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "id": "d9a7c3e3-331c-46c5-91ba-7fb899ff93de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 24ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.00036795, 0.17296182, 0.04106217, 0.04856793, 0.03616836,\n",
       "        0.04449897, 0.03559168, 0.05467949, 0.11750646, 0.16739662,\n",
       "        0.28119853]], dtype=float32)"
      ]
     },
     "execution_count": 333,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_case2 = np.array([padded[48],])\n",
    "model.predict(test_case2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "id": "05af121a-301c-4975-927d-3983ade48cfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 28ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.00036795, 0.17296182, 0.04106217, 0.04856793, 0.03616836,\n",
       "        0.04449897, 0.03559168, 0.05467949, 0.11750646, 0.16739662,\n",
       "        0.28119853]], dtype=float32)"
      ]
     },
     "execution_count": 334,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_case2 = np.array([padded[1],])\n",
    "model.predict(test_case2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "714c5889-452d-4987-99a5-9dbd2dfee2d0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "048b6389-ef08-4866-8289-a4b8138f06ae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
